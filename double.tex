%\documentclass[a4paper,10pt]{article}
%\documentclass[draftcls, onecolumn, 11pt]{IEEEtran}
%\documentclass[journal, onecolumn, 11pt]{IEEEtran}
\documentclass[journal]{IEEEtran}
%\documentclass[correspondence,9pt]{IEEEtran}


\usepackage{mathbf-abbrevs}
\usepackage{amsmath}
\DeclareMathOperator{\argmin}{\arg\!\min}

\input{defs}

%opening
\title{On the error performance of the $A_n$ lattices}
\author{Robby McKilliam, Ramanan Subramanian, Emanuele Viterbo, I. Vaughan L. Clarkson
 \thanks{Copyright (c) 2012 IEEE. Personal use of this material is permitted.  However, permission to use this material for any other purposes must be obtained from the IEEE by sending a request to pubs-permissions@ieee.org.  Robby~McKilliam and Ramanan Subramanian are with the Institute for Telecommunications Research, The University of South Australia, SA, 5095.  Emanuele Viterbo is with the Department of Electrical and Computer Systems Engineering, Monash University, Melbourne, VIC, Australia.   Vaughan~Clarkson is with the School of Information Technology \& Electrical Engineering, The University of Queensland, QLD., 4072, Australia.}
}

\begin{document}

\newcommand{\calR}{\mathcal{R}}
\newcommand{\hist}{\operatorname{hist}}

\maketitle

\begin{abstract}
We consider the root lattice $A_n$ and derive explicit recursive formulae for the moments of its Voronoi cell.  These formulae
enable accurate prediction of the error probability of lattice codes constructed from $A_n$.
\end{abstract}

\begin{IEEEkeywords}
Lattices, lattice decoding, root lattice, probability of error, Voronoi cell.
\end{IEEEkeywords}

\section{Introduction}\label{sec:introduction}


The \emph{root lattices} $A_n$, $D_n$, $E_6$, $E_7$ and $E_8$ have attracted particular attention as structured codes for the additive white Gaussian noise (AWGN) channel~\cite{SPLAG}. The highly symmetric structure of these lattices provides the grounds for extremely efficient encoding and decoding algorithms~\cite{Conway1982FastQuantDec,McKilliam2009CoxeterLattices,McKilliam2008}.  In this paper we consider codes constructed from the root lattice $A_n$ and derive formulae for accurately predicting the performance of these codes.  This is achieved by deriving formulae for the \emph{moments} of the \emph{Voronoi cell} of $A_n$.  Conway and Sloane suggested this approach to compute the quantizing constants (second order moments) of the root lattices~\cite{Conway1982VoronoiRegions}.  In this paper we extend their technique to compute the moments of any order for $A_n$.

In two dimensions $A_2$ is the hexagonal lattice and in three dimensions $A_3$ is the face-centered cubic lattice.  These are the densest sphere packings in dimensions two and three and our results automatically include low dimensional codes constructed using these packings.  In general, the lattice $A_n$ does not produce asymptotically good codes in large dimensions, but does offer a coding gain in small dimensions.  For these cases, we provide an error probability expression that can be computed to any degree of accuracy at any finite signal-to-noise ratio.
%We are hopeful that the techniques developed here may be applied to other lattices that do produce good codes.  In particular our techniques might apply to the Coxeter lattices $A_n^m$ of which the root lattice $E_8 \simeq A_8^3$ is a member~\cite{Coxeter1951,Martinet2003,McKilliam2009CoxeterLattices}.

This paper is organised as follows.  In Section~\ref{sec:latt-latt-codes} we give a brief overview of lattices and codes constructed from them, i.e., \emph{lattice codes}.  We describe lattice decoding and show how the probability of coding error can be expressed in terms of the moments of the \emph{Voronoi cell} of the lattice used.  Section~\ref{sec:main-result} states the main result, describing recursive formula to compute the moments of the Voronoi cell of $A_n$.  Section~\ref{sec:lattice-a_n} describes the lattice $A_n$ and some of its properties.  An important property for our purposes is that the Voronoi cell of $A_n$ is precisely the orthogonal projection of an $(n+1)$-dimensional hypercube onto a hyperplane orthogonal to one of its vertices~\cite{McKilliam2009CoxeterLattices,McKilliam2010thesis}.
 %This result was previously known~\cite{McKilliam2009CoxeterLattices,McKilliam2010thesis}.  The proof is short and we give it again here so that this paper is self contained.
In Section~\ref{sec:integr-funct-over} we use this property to show how integrals over the Voronoi cell of $A_n$ can be expressed as integrals over the $(n+1)$-dimensional hypercube. These integrals are solvable and we use them to obtain the moments of the Voronoi cell in Section~\ref{sec:powers-eucl-norm}.  In Section~\ref{sec:results-simulations} we plot the probability of error versus signal to noise ratio for codes constructed from the lattices $A_1 \simeq \ints$, $A_2$, $A_3 \simeq D_3$ and $A_4$, $A_5$ and $A_8$.  We also plot the results of Monte-Carlo simulations that support our analytical results.
%An advantage of the analytical results is that the probability of error can calculated at high SNR, when the probabilty of error is small.  This is in contrast to Monte-Carlo simulations that are computationally infeasible at when the probability of error is small.  We display the performance of these lattice codes




\section{Lattices, lattice codes, and lattice decoding} \label{sec:latt-latt-codes}


A \term{lattice}\index{lattice}, $\Lambda$, is a discrete subset of points in $\reals^m$ such that
\[
   \Lambda = \{\xbf = \Bbf\ubf \mid \ubf \in \ints^n \}
 \]
 where $\Bbf \in \reals^{m \times n}$ is an $m \times n$ matrix of rank $n$, called a \term{generator matrix} or \term{basis matrix} or simply generator or basis. In particular, the set of $n$-tuples of integers $\ints^n$ is a lattice (with the identity matrix as a generator) and we call this the~\emph{integer lattice}. A lattice $\Lambda$ associated with a rank-$n$ generator matrix $\mathbf{B}$ is said to be $n$-dimensional. If the generator is square, i.e. $m = n$, then the lattice points span $\reals^n$ and we say that the lattice is \term{full rank}. If $\Bbf$ has more rows than columns, i.e. $m > n$, then the lattice points lie in an $n$-dimensional subspace of $\reals^m$. For any lattice $\Lambda$ with an $m \times n$ generator matrix, we define $\mathcal{S}_{\Lambda}$ to be the hyperplane spanned by the columns of the generator matrix. %It is easy to see that $\mathcal{S}_\Lambda$ is then the $n$-dimensional subspace containing the lattice $\Lambda$.

The (open) \term{Voronoi cell}, denoted $\vor(\Lambda)$, of a lattice $\Lambda$ is the subset of $\mathcal{S}_{\Lambda}$ containing all points nearer (in Euclidean distance) to the lattice point at the origin than any other lattice point. The Voronoi cell is an $n$-dimensional convex polytope that is symmetric about the origin.  It is convenient to modify this definition of the Voronoi cell slightly so that the union of translated Voronoi cells $\cup_{\xbf \in \Lambda}\vor(\Lambda) + \xbf$ is equal to  $\mathcal{S}_{\Lambda}$.  That is, the Voronoi cell tessellates when translated by points in $\Lambda$.  To ensure this we require that if a face of $\vor(\Lambda)$ is open, then its opposing face is closed. Specifically, if $\xbf \in \vor(\Lambda)$ is on the boundary of $\vor(\Lambda)$ then $-\xbf \notin \vor(\Lambda)$.  We will not specifically define which opposing face is open and which is closed as the results that follow hold for any choice of open and closed opposing faces.

The Voronoi cell encodes many interesting lattice properties such as the packing radius, covering radius, kissing number, minimal vectors, center density, thickness, and the normalized second moment (or quantizing constant)~\cite{Viterbo_diamond_cutting_1996, SPLAG}. The error probability of a lattice code can also be evaluated from the Voronoi cell as we will see.  There exist algorithms to completely enumerate the Voronoi cell of an arbitrary lattice~\cite{Viterbo_diamond_cutting_1996,Sikiric_complex_algs_vor_cells_2009,Sikiric_vor_reduction_covering_2008,Valentin2003_coverings_tilings_low_dimension}.  In general these algorithms are only computationally feasible when the dimension is small (approximately $n \leq 9$).  Even with a complete description of the Voronoi cell it is not necessarily easy to compute the probability of coding error.

The Voronoi cell is linked with the problem of \emph{lattice decoding}.  Given some point $\ybf \in \reals^n$ a \emph{lattice decoder} (or \emph{nearest lattice point algorithm}) returns the lattice point in $\Lambda$ that is nearest to $\ybf$~\cite{Agrell2002}.  Equivalently it returns the lattice point $\xbf$ such that the translated Voronoi cell $\vor(\Lambda) + \xbf$ contains $\ybf$.  Computationally lattice decoding is known to be NP-hard under certain conditions when the lattice itself, or rather a basis thereof, is considered as an additional input parameter~\cite{micciancio_hardness_2001}. Nevertheless, algorithms exist that can compute the nearest lattice point in reasonable time if the dimension is small (approximately $n \leq 60$). One such algorithm is the \term{sphere decoder}~\cite{Viterbo_sphere_decoder_1999,Pohst_sphere_decoder_1981,Agrell2002,Jalden2005_sphere_decoding_complexity}.
 %Kannan~\cite{Kannan1987_fast_general_np} suggested a different approach that is known to be asymptotically faster than the sphere decoder.
A good overview of these techniques is given by Agrell~et.~al.~\cite{Agrell2002}. Fast nearest point algorithms are known for specific lattices~\cite{Conway1982FastQuantDec, McKilliam2008,McKilliam2009CoxeterLattices,Vardy1993_leech_lattice_MLD}. For example, the root lattices $D_n$ and $A_n$ and their dual lattices $D_n^*$ and $A_n^*$ can be decoded in linear-time, i.e. in a number of operations of order $O(n)$~\cite{Conway1982FastQuantDec,McKilliam2009CoxeterLattices}.

%Approximate algorithms for computing the nearest point have also been studied.  A classic example is \term{Babai's nearest plane algorithm}~\citep{Babai1986}\index{Babai's nearest plane algorithm}, which requires $O(n^4)$ arithmetic operations in the worst case where $n$ is the dimension of the lattice and only $O(n^2)$ if the lattice basis is \term{Lov\'asz reduced}~\citep{Lenstra1982}\index{Lov\'asz reduced}. Recently, various approximate techniques for solving the nearest lattice point problem have been motivated by applications to MIMO communications.  An example is the \term{$K$-best algorithm}\index{K-best algorithm}~\citep{Zhan2006_K_best_sphere_decoder} that works similarly to the sequential $M$-algorithm~\citep{Anderson1984_seq_coding_alg} used in coding theory. Yet another example is the \term{fixed sphere decoder}~\citep{Jalden2009_error_prob_fixed_sphere_decoder,Barbero2008_fixed_sphere_decoder}. In this thesis we will make use of Babai's nearest plane algorithm, the sphere decoder and the $K$-best algorithm.  We will not detail the workings of these algorithms as excellent descriptions already exist in the literature cited above.


%For each lattice point $\ybf \in \Lambda$ there exists a Voronoi cell containing those point from $\reals^n$ nearer to $\ybf$ that any other lattice point.  Due to the structure of the lattice the Voronoi cell of each lattice point is the same shape.  Denote by $\vor(\Lambda)$ the Vornoi cell of the lattice point at the origin. NEAREST POINT PROBLEM.
\newcommand{\calX}{\mathcal X}
\newcommand{\calC}{\mathcal C}
Lattices can be used to construct \emph{lattice codes}.  A lattice code $\calC$ of dimension $n$ is a finite subset of points of some lattice $\Lambda$ in $\reals^n$.  Each point in $\calC$ is called a \emph{codeword} and represents a particular signal.  There are infinitely many ways to choose a finite subset from a lattice, but common approaches make use of a bounded subset of $\reals^n$, called a \emph{shaping region} $S \subset \reals^n$.  The codewords are given by those lattice points inside the shaping region, that is, $\calC = S \cap \Lambda.$  Common choices of shaping region are $n$-dimensional spheres, spherical shells, hypercubes, or the Voronoi cell of a \emph{sublattice} of $\Lambda$~\cite{Buda1989_some_opt_codes_structure,Erex2004_lattice_decoding,Conway1983VoronoiCodes}.  The number of codewords is denoted by $\abs{\calC}$.  If each codeword is transmitted with equal probability then the rate of the code is $R = \frac{1}{n}\log_2{\abs{\calC}}$ bits per codeword.  The average power of the code is $P = \frac{1}{\abs{\calC}}\sum_{\cbf \in \calC}\|\cbf\|^2$. 

In the AWGN channel the received signal takes the form
\[
\ybf = \cbf + \wbf
\]
where $\ybf \in \reals^n$, $\cbf \in \calC$ and $\wbf$ is a vector of independent and identically distributed Gaussian random variables with variance $\sigma^2$.  If the receiver employs maximum likelihood decoding then the estimator of $\cbf$ given $\ybf$ at the receiver is
\begin{equation}\label{eq:mldecoder}
\hat{\cbf}_{\text{ML}} = \underset{\cbf \in \calC}{\operatorname{argmin}}\;\| \ybf - \cbf \|^2,
%\hat{\cbf} &=& \mbox{arg~}\min_{\cbf \in \calC} \| \ybf - \cbf \|^2.
\end{equation}
that is, the receiver computes the codeword in $\calC$ nearest in Euclidean distance to the received signal $\ybf$.  Assuming that each codeword is transmitted with equal probability, then the probability of correct maximum likelihood decoding is
\[
P_{\text{ML}} = \frac{1}{\abs{\calC}}\sum_{\cbf \in \calC}\prob( \hat{\cbf}_{\text{ML}} = \cbf ).
\]

Maximum likelihood decoding is typically computationally complex and it is preferable to use lattice decoding~\cite{Agrell2002,Erex2004_lattice_decoding}.  The estimator of $\cbf$ is then,
\begin{equation}\label{eq:latticedecoder}
\hat{\cbf} = \underset{\cbf \in \Lambda}{\operatorname{argmin}}\;\| \ybf - \cbf \|^2,
%\hat{\cbf} &=& \mbox{arg~}\min_{\cbf \in \calC} \| \ybf - \cbf \|^2.
\end{equation}
that is, the receiver computes the lattice point in $\Lambda$ nearest in Euclidean distance to the received signal $\ybf$.  Equivalently, $\hat{\cbf}$ is the lattice point such that $\ybf \in \vor(\Lambda) + \hat{\cbf}$.  Note that with lattice decoding the decoded lattice point $\hat{\cbf}$ is not guaranteed to be inside the code $\calC$.

Correct lattice decoding occurs when $\hat{\cbf} = \cbf$, or equivalently when $\ybf \in \vor(\Lambda) + \cbf$, or equivalently when $\wbf \in \vor(\Lambda)$, i.e. when the noise $\wbf$ is inside the Voronoi cell of the lattice.  Assuming that each codeword is transmitted with equal probability then the probability of correct lattice decoding is
\begin{align}
P_C &= \frac{1}{\abs{\calC}}\sum_{\cbf \in \calC} \prob( \hat{\cbf} = \cbf ) \nonumber \\
&= \frac{1}{\abs{\calC}}\sum_{\cbf\in \calC} \prob( \cbf + \wbf \in \vor(\Lambda) + \cbf )  \nonumber \\
&= \prob(\wbf \in \vor(\Lambda) ) \nonumber \\
&=   \frac{1}{(\sqrt{2\pi}\sigma)^n} \int_{\vor(\Lambda)}e^{-\|\xbf\|^2 / 2\sigma^2 } d\xbf. \label{eq:PEgaussian}
\end{align}
The probability of error is $P_E = 1 - P_C$.  The probability of correct lattice decoding is smaller than the probability of correct maximum likelihood decoding.  However, as the size of the code $\abs{\calC}$ increases, the proportion of codewords near the boundary of the shaping region becomes small, and $P_C$ converges to $P_{\text{ML}}$.

By expanding $e^x = 1  + x + \frac{x^2}{2} + \dots$ according to its Maclaurin series we obtain
\begin{align}
P_C  &= \frac{1}{(\sqrt{2\pi}\sigma)^n}\int_{\vor(\Lambda)} 1
- \frac{\|\xbf\|^2}{2\sigma^2} + \frac{\left(\|\xbf\|^2\right)^2}{
4\sigma^42!} - \dots d\xbf \nonumber \\
&= \frac{1}{(\sqrt{2\pi}\sigma)^n} \sum_{m=0}^\infty
\frac{(-1)^m}{2^m\sigma^{2m}m!} \int_{\vor(\Lambda)} \|\xbf\|^{2m}
d\xbf.  \label{eq:summomentproberror}
\end{align}
So, to obtain arbitrarily accurate approximations to the probability of error it is enough to know the values of $\int_{\vor(\Lambda)} \|\xbf\|^{2m} d\xbf$ for $m=1,2\dots$ for some sufficiently large $m$.  The number of terms required increases as the noise variance gets smaller.  This implies that the bound with a fixed number of terms is not asymptotically tight but is very accurate up to a finite signal-to-noise ratio.  We call these terms the \emph{moments} of $\vor(\Lambda)$.

\newcommand{\calM}{M}
In this paper we focus on $n$-dimensional lattice codes constructed from the family of lattices called $A_n$ and we derive expressions for the moments
\[
 \calM_n(m) = \int_{\vor(A_n)} \|\xbf\|^{2m} d\xbf.
\]
These can be summed in (\ref{eq:summomentproberror}) to give arbitrarily accurate approximations for the probability of error.



% We now briefly describe our setting for coding using lattices.  Let $C$ denote an arbitrary set of codewords, each codeword a vector from $\reals^n$.  The rate of this code is $\log_2(\abs{C})$ bits per dimension (or symbol) where $\abs{C}$ is the number of codewords in $C$.  To each codeword $\ybf \in C$ there exists a Voronoi cell, or nearest neighbour region, containing all those points from $\reals^n$ nearer in Euclidean distance to $\ybf$ than any other codeword in $C$.  Denote by ${\mathcal D}(\ybf)$ the Vornoi cell of $\ybf$.  The average probability of correct decoding in the Gaussian channel is
% \[
% P_E(C) = \frac{1}{(\sqrt{2\pi}\sigma)^n \abs{C}} \sum_{\ybf \in C} \int_{{\mathcal D}(\ybf)} e^{\|\xbf - \ybf\|^2 / 2\sigma^2 } d\xbf.
% \]
% When $n$ is large it is known that randomly generated codes approach channel capacity.  However, random codes are not practical when $n$ is large as decoding and encoding operations require enumeration over each codeword in $C$ and for a fixed rate the number of codewords grow exponentially in $n$.  For this reason, code with structure are prefered.

% One way to prescribe structure is to take codewords from a \emph{lattice}.

% A code is constructed from a lattice $\Lambda$ by taking a finite subset of lattice points.  Typically this is achieved using a region of finite volume $R \subset \reals^n$, called the \emph{shaping region}.  The codewords are all those lattice points that intersect with $R$, i.e. our code is $C = \Lambda \cap R$.  An uncountable number of shaping regions are possible  but spheres, sphereical shells and hypercubes are common.  Another possiblity is to choose as $R$, the Voronoi cell $\vor{\Lambda'}$ where $\Lambda'$ is a sublattice of $\Lambda$.  A specific advantage of this approach is that encoding and decoding can be efficiently performed if there is a fast algorithm for computing a nearest point in $\Lambda$~\cite{Conway1982FastQuantDec}.

% A caveat with this construction is that the Voronoi cells of the codewords in $C$ are no longer nessecarily similar to the Voronoi cell of $\Lambda$.  This is a results of taking only a finite set of lattice points.  Infact some of the codewords will have unbounded Voronoi cells.  The problem is that now

% Given a lattice code $C = \Lambda \cap R$ and a recieved codeword $\ybf = \xbf + \wbf$ where $\xbf \in C$ and $\wbf$ is a vector of independent and identically distributioned Gaussian random variables with variance $\sigma^2$, the maximum likelihood decoder returns the lattice point in $C$ that is nearest to $\ybf$ in Euclidean distance.  A difficult

\begin{figure*}[bt]
% ensure that we have normalsize text
%\normalsize
\small
% Store the current equation number.
%\setcounter{MYtempeqncnt}{\value{equation}}
% Set the equation number to one less than the one
% desired for the first equation here.
% The value here will have to changed if equations
% are added or removed prior to the place these
% equations are referenced in the main text.
%\setcounter{equation}{5}
\begin{align*}
\calM_n(3) &= \frac{1960 n + 2142 n^2 + 2681 n^3 + 1423 n^4 + 399 n^5 + 35 n^6}{60480 (1 + n)^{5/2}} \\
\calM_n(4) &= \frac{93744 n + 34356 n^2 + 112172 n^3 + 89343 n^4 + 53224 n^5 + 17246 n^6 + 2940 n^7 + 175 n^8}{3628800 (1 + n)^{7/2}} \\
\calM_n(5) &= \frac{3577728 n - 1825648 n^2 + 2410804 n^3 + 1569392 n^4 + 1644423 n^5 + 906105 n^6+341550 n^7+75526 n^8+8855 n^9+385 n^{10}}{95800320 (1 + n)^{9/2}}
\end{align*}
% Restore the current equation number.
%\setcounter{equation}{\value{MYtempeqncnt}}
% IEEE uses as a separator
\hrulefill
% The spacer can be tweaked to stop underfull vboxes.
\vspace*{4pt}
\end{figure*}


\section{The main result}\label{sec:main-result}

We now state our main result.  The moment $\calM_n(m)$ of the lattice $A_n$ satisfies
\begin{equation}\label{eq:theCmformula}
\frac{\calM_n(m)}{m!} = \frac{n\sqrt{n+1}}{n+2m}\sum_{k=0}^{m}\sum_{a =0}^{k}\sum_{b=0}^{k-a} \frac{G(n-1,a,2k - 2a - b)}{H(n,m,k,a,b)},
\end{equation}
where the function
\[
H(n,m,k,a,b) = \frac{(n+1)^{m-a}a!(m-k)!b! (k-a-b)!}{(-1)^{k-a}2^{b} n^{m-k}},
\]
and the function $G(n,c,d)$ satisfies the recursion
\begin{equation}\label{eq:theGrecursion}
G(n,c,d) = \sum_{c'=0}^{c} \sum_{d'=0}^{d} \binom{c}{c'}\binom{d}{d'} \frac{G(n-1,c-c',d-d')}{2c'+d'+1},
\end{equation}
with the initial conditions
\[
G(1,c,d) = \frac{1}{2c+d+1} \qquad \text{and} \qquad G(n,0,0) = 1.
\]
For fixed $m$ it is possible to solve this recursion in $n$ and obtain formula for the $\calM_n(m)$ in terms of $n$ (see Appendix~\ref{sec:solv-this-recurs}).  The first three such formula are:
\begin{align*}
\calM_n(0) &= \sqrt{n+1} \qquad \text{the volume of~}\vor(A_n),\\
\calM_n(1) &= \frac{n(n+3)}{12\sqrt{n+1}} \qquad \text{the 2nd moment~ \cite[p. 462]{SPLAG}}, \\
\calM_n(2) &=  \frac{50 n + 55 n^2 + 34 n^3 + 5 n^4}{720 (1 + n)^{3/2}}
%\calM_n(3) &= \frac{1960 n + 2142 n^2 + 2681 n^3 + 1423 n^4 + 399 n^5 + 35 n^6}{60480 (1 + n)^{5/2}}, \\
%\calM_n(4) &= \frac{93744 n + 34356 n^2 + 112172 n^3 + 89343 n^4 + 53224 n^5 + 17246 n^6 + 2940 n^7 + 175 n^8}{3628800 (1 + n)^{7/2}}.
\end{align*}
and the next three formula are displayed at the top of this page.  We have explicitly tabulated these formula for $m=0$ to $40$. For larger $m$ direct evaluation for specific $n$ from the recursive formula is preferable.  We will derive these results in Section~\ref{sec:powers-eucl-norm}, but first need some properties of the lattice $A_n$.

\section{The lattice $A_n$}\label{sec:lattice-a_n}
Let $H$ be the hyperplane orthogonal to the all ones vector of length $n+1$, denoted by $\onebf$, that is
\[
\onebf = \left[ \begin{array}{cccc} 1 & 1 & \cdots & 1 \end{array} \right]^\prime,
\]
where superscript $^\prime$ indicates the transpose.  Any vector in $H$ has the property that the sum (and therefore the mean) of its elements is zero and for this reason $H$ is often referred to as the \emph{zero-sum plane} or the \emph{zero-mean plane}.
The lattice $A_n$ is the intersection of the integer lattice $\ints^{n+1}$ with the zero-sum plane, that is
\begin{equation}
\label{eq:An_sub_Zn}
  A_{n} = \ints^{n+1} \cap H = \big\{ \xbf \in \ints^{n+1} \mid \dotprod{\xbf}{\onebf} = 0  \big\}.
\end{equation}
Equivalently, $A_n$ consists of all of those points in $\ints^{n+1}$ with coordinate sum equal to zero.
% A generator matrix for $A_n$ is the $(n+1)\times n$ matrix
% \[
% \left[ \begin{array}{rrrrrrr}
% 1 & 0 & 0 &  \cdots & 0 & 0 \\
% -1 & 1 & 0 &  \cdots & 0 & 0 \\
% 0 & -1 & 1 &  \cdots & 0 & 0 \\
% 0 & 0 & -1 & \cdots & 0 & 0 \\
% \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
% 0 & 0 & 0 & \cdots & -1 & 1 \\
% 0 & 0 & 0 & \cdots & 0 & -1  \\
% \end{array} \right].
% \]
The lattice has $n(n+1)$ minimal vectors, each of squared Euclidean length $2$, so the packing radius is $\frac{1}{\sqrt{2}}$.  The $n$-volume of the Voronoi cell $\vor(A_n)$ is $\sqrt{n+1}$~\cite[p. 108]{SPLAG}.  In two dimensions $A_2$ is the hexagonal lattice (Figure~\ref{fig:hexlatfig}), and in three dimension $A_3$ is the body centered cubic lattice~\cite[p. 108]{SPLAG}.  %These are the densest known sphere packings in dimensions two and three.

\begin{figure}[tbp]
	\centering
		\includegraphics[scale=1.2]{figs/hexlatfig-1.mps}
		\caption{The hexagonal lattice $A_2$ with its sphere packing and Voronoi cell.  The Voronoi cell is a regular hexagon.}
		\label{fig:hexlatfig}
\end{figure}

The Voronoi cell of $A_n$ is closely related to the $(n+1)$-dimensional hypercube $\vor(\ints^{n+1})$ as the next theorem will show.  This result has appeared previously~\cite{McKilliam2009CoxeterLattices,McKilliam2010thesis}, but we repeat it here so that this paper is self contained.  We denote by
\[
\Qbf = \Ibf - \frac{\onebf\onebf^\prime}{\onebf^\prime \onebf} = \Ibf - \frac{\onebf\onebf^\prime}{n+1}
\]
the projection matrix orthogonal to $\onebf$ (i.e. into the zero-sum plane) where $\Ibf$ is the $n+1$ by $n+1$ identity matrix.  Given a set $S$ of vectors from $\reals^{n+1}$ we write $\Qbf S$  to denote the set with elements $\Qbf \sbf$ for all $\sbf \in S$, i.e. the set containing the projection of the vectors from $S$.

\begin{lemma} \label{lem:QVorZnsubsetVorAn}
The projection of $\vor(\ints^{n+1})$ into the zero-sum plane is a subset of $\vor(A_{n})$.  That is,
\[
\Qbf\vor(\ints^{n+1}) \subseteq \vor(A_{n}).
\]
\end{lemma}
\begin{IEEEproof}
Let $\ybf \in \vor(\ints^{n+1})$.  Decompose $\ybf$ into orthogonal components so that $\ybf = \Qbf \ybf + t \onebf$ for some $t \in \reals$.  Then $\Qbf\ybf \in \Qbf\vor(\ints^{n+1})$.  Assume that $\Qbf\ybf \notin \vor(A_n)$.  Then there exists some $\xbf \in A_n$ such that
\begin{align*}
\|\xbf - \Qbf\ybf\|^2 < \|\zerobf - \Qbf\ybf\|^2 & \Rightarrow \|\xbf - \ybf + t\onebf\|^2 < \|\ybf - t\onebf\|^2 \\
%& \Rightarrow \|\xbf - \ybf\|^2 + 2t(\xbf - \ybf)'\onebf + t^2\|\onebf\|^2 < \|\ybf\|^2 - 2t\ybf'\onebf + t^2\|\onebf\|^2 \\
& \Rightarrow \|\xbf - \ybf\|^2 + 2t\xbf'\onebf < \|\ybf\|^2.
\end{align*}
By definition \eqref{eq:An_sub_Zn} $\xbf'\onebf = 0$ so $\|\xbf - \ybf\|^2 < \|\ybf\|^2$.  This violates that $\ybf \in \vor(\ints^{n+1})$ and hence $\Qbf\ybf \in \vor(A_n)$.\footnote{This proof can be generalised to show that for any lattice $L$ and hyperplane $P$ such that $P\cap L$ is also a lattice it is true that $p\vor(L) \subseteq \vor(L \cap P)$ where $p$ indicates the orthogonal projection into $P$~\cite[Lemma~2.1]{McKilliam2010thesis}.}
\end{IEEEproof}

\begin{theorem}  \label{thm:VorAn=QVorZn1}
The projection of $\vor(\ints^{n+1})$ into the zero-sum plane is equal to $\vor(A_{n})$. That is,
\[
\vor(A_n) = \Qbf\vor(\ints^{n+1}).
\]
\end{theorem}
\begin{IEEEproof}
Let $\ebf_i$ denote a vector with $i$th element equal to one and the remaining elements zero.  The $n$-volume of $\vor(A_n)$ is $\sqrt{n + 1}$.  From Burger~et.~al.~\cite[Theorem 1.1]{Burger1996} we find that the $n$-volume of the projected hypercube $\Qbf\vor(\ints^{n+1})$ is equal to
\[
\sum_{i = 1}^{n+1} \frac{\dotprod{\onebf}{\ebf_i}}{\|\onebf\|} =  \sum_{i = 1}^{n+1} \frac{1}{\sqrt{n+1}} = \sqrt{n + 1}
\]
also. It follows from Lemma~\ref{lem:QVorZnsubsetVorAn} that $\Qbf\vor(\ints^{n+1}) \subseteq \vor(A_n)$, so, because the volumes are the same, and because $\vor(A_n)$ and $\Qbf\vor(\ints^{n+1})$ are polytopes, we have $\vor(A_n) = \Qbf\vor(\ints^{n+1})$.
\end{IEEEproof}

\begin{figure*}[tp]
	\centering
		\includegraphics[scale=1.6]{figs/cuberothex-1.mps}
		\caption{Orthogonal projection of a cube as it is rotated about its center.  The figure on the left is the view of a cube from side on, and the boundary is a square.  When the cube is rotated the boundary becomes a hexagon.  The hexagon is regular when the cube is viewed along one of its vertices (the rightmost figure).  The regular hexagon is the Voronoi cell of the hexagonal lattice $A_2$ (see~Figure~\ref{fig:hexlatfig}).  Every 2-dimensional zonotope is also unimodular so the boundary of each of the figures above can be used to tile 2-dimensional Euclidean space~\cite{McMullen_space_tiling_zonotopes_1975}.}
		\label{fig:cuberothex}
\end{figure*}

This theorem asserts that the Voronoi cell of the lattice $A_n$ is the $n$-dimensional polytope that results from orthogonally projecting the $(n+1)$-dimensional hypercube into the zero-sum plane.  Results of this type have been studied previously.  A polytope that is the orthogonal projection of a hypercube is called a \emph{zonotope}~\cite[p.~313]{surveys_combin_zonotopes_1997}~\cite{McMullen_space_tiling_zonotopes_1975}.  Figure~\ref{fig:cuberothex} depicts some 2-dimensional zonotopes.  A zonotope is \emph{unimodular} if it can be used to tile (or tesselate) Euclidean space.  Such a tesselation naturally gives rise to a lattice, a so called \emph{zonotopal lattice}~\cite{Vallentin_space_tiling_zonotope_2004}.  The lattice $A_n$ is a zonotopal lattice and the techniques in this paper can potentially be extended to other zonotopal lattices. 

\section{Integrating a function over $\vor(A_n)$}\label{sec:integr-funct-over}

We would like to be able to integrate functions over the Voronoi cell of $A_n$.  Consider a function $f : \reals^{n+1} \mapsto \reals$.  The definition we have made for $A_n$ in Section~\ref{sec:lattice-a_n} places it in the $n$-dimensional zero-sum plane, lying in $\reals^{n+1}$.  The Voronoi cell is a subset of the zero-sum plane that has zero $(n+1)$-dimensional volume.  So, the volume integral $\int_{\vor(A_n)} f(\xbf) d \xbf$ is equal to zero.  This is not what we intend.  By an appropriate change of variables it would be possible to write the Voronoi cell $\vor(A_n)$ in an $n$-dimensional coordinate system, and then integrate.  However, we find the following approach simpler.  Given a set $S$ of vectors from the zero-sum plane, let $S \times \onebf$ denote the set of elements that can be written as $\xbf + \ybf$ where $\xbf \in S$ and $\ybf = k\onebf$ for some $k \in [-\nicefrac{1}{2},\nicefrac{1}{2}]$.  If $S$ has $n$-volume equal to $V$ then the $(n+1)$-volume of $S\times\onebf$ is equal to $V\|\onebf\| = V \sqrt{n+1}$.  Now, the integral over the Voronoi cell can be written as
\begin{equation}\label{eq:vorfint}
\begin{split}
\frac{1}{\sqrt{n+1}} &\int_{\vor(A_n) \times \onebf} f(\Qbf\xbf) d\xbf \\
&= \frac{1}{\sqrt{n+1}} \int_{\Qbf\vor(\ints^{n+1}) \times \onebf} f(\Qbf\xbf) d\xbf.
\end{split}
\end{equation}
It is not immediately clear how an integral over $\vor(A_n) \times \onebf$ should be performed.  Consider the following simpler integral over the hypercube $\vor(\ints^{n+1})$,
\begin{equation}\label{eq:unormalised}
\int_{\vor(\ints^{n+1})} f(\Qbf\xbf) d\xbf.
\end{equation}
This integral is not equal to~\eqref{eq:vorfint} because, although $\Qbf\xbf$ is always an element of $\vor(A_n)$, the integral is not uniform over $\vor(A_n)$.  To see this, consider some $\xbf \in \vor(\ints^{n+1})$ and let $x_{\text{max}}$ be the maximum element of $\xbf$ and $x_{\text{min}}$ be the minimum element.  Then $\xbf +  k \onebf \in \vor(\ints^{n+1})$ for those $k \in [-\nicefrac{1}{2} - x_{\text{min}}, \nicefrac{1}{2} - x_{\text{max}})$.  The length of this interval is $1 - x_{\text{max}} + x_{\text{min}}$ so the (one dimensional) volume of the set of points in $\vor(\ints^{n+1})$ that, once projected orthogonally to $\onebf$, are equal to $\Qbf\xbf$ is
\[
\|\onebf\|(1 - x_{\text{max}} + x_{\text{min}}) = \sqrt{n+1}(1 - x_{\text{max}} + x_{\text{min}}).
\]
The integral~\eqref{eq:vorfint} can be obtained by normalising~\eqref{eq:unormalised} by this length, that is,
\begin{equation}\label{eq:vorfintafternorm}
\begin{split}
\frac{1}{\sqrt{n+1}} &\int_{\vor(A_n) \times \onebf} f(\Qbf\xbf) d\xbf \\
&=  \int_{\vor(\ints^{n+1})} \frac{f(\Qbf\xbf)}{\sqrt{n+1}(1 - x_{\text{max}} + x_{\text{min}})}  d\xbf.
\end{split}
\end{equation}
The primary advantage of this integral is that the bounds are given by the $(n+1)$-dimensional hypercube $\vor(\ints^{n+1})$.\footnote{A caveat applies when $x_{\text{max}} = \nicefrac{1}{2}$ and $x_{\text{min}} = -\nicefrac{1}{2}$ and the denominator in the integral in~\eqref{eq:vorfintafternorm} is equal to zero.  In this case the interval $[-\nicefrac{1}{2} - x_{\text{min}}, \nicefrac{1}{2} - x_{\text{max}})$ is empty and we specify that these points do not contribute to the integral.}

Let us now restrict $f(\xbf)$ so that it depends only on the magnitude $\|\xbf\|$, for example $f(\xbf) = \|\xbf\|^{2m}$ could be a power of the Euclidean norm of $\xbf$.  Now $f(\xbf)$ is invariant to permutation of $\xbf$.  Let $\xbf$ be such that $x_1$ is the maximum element and $x_2$ is the minimum element.  Our integral is now equal to
\begin{align*}
\frac{n (n+1)}{\sqrt{n+1}} \int^{1/2}_{-1/2} \int^{x_1}_{-1/2}  \int^{x_1}_{x_2} \cdots \int^{x_1}_{x_2} &\frac{f(\Qbf\xbf)}{1 - x_{1} + x_{2}}  \\
&\hspace{0.5cm} dx_{n+1} \, \dots \, dx_2 \, dx_1.
\end{align*}
The factor $n(n+1)$ arises because there are $n(n+1)$ ways to place two elements (i.e. $x_1$ and $x_2$) into $n+1$ positions.

We can make further simplifications.  Letting $t = x_1 - x_2$ and $y = x_1 + 1/2$ and changing variables, gives
\begin{align*}
n \sqrt{n+1} \int^{1}_{0} \int^{y}_{0}  \int^{y - 1/2}_{y - t - 1/2} \cdots \int^{y-1/2}_{y-t-1/2} &\frac{f(\Qbf\xbf )}{1 - t}  \\
&dx_{n+1} \, \dots \, dx_3 \, dt \, dy,
\end{align*}
and letting $w_{i-2} = x_i - y + 1/2 + t$ for $i = 3,\dots,n+1$ gives
\begin{equation}\label{eq:intwewilluse}
n \sqrt{n+1} \int^{1}_{0} \int^{y}_{0}  \int^{t}_{0} \cdots \int^{t}_{0} \frac{f(\Qbf\xbf )}{1 - t}  dw_{n-1} \, \dots \, dw_1 \, dt \, dy.
\end{equation}
Observe that $\xbf = \wbf + (y - t - \nicefrac{1}{2})\onebf$ where $\wbf$ is the column vector
\[
\wbf = [t, 0, w_1, w_2, \dots, w_{n-1}]^\prime.
\]
Projecting orthogonal to $\onebf$ gives $\Qbf\xbf = \Qbf \wbf$.  Interestingly $\wbf$ does not contain $y$ so the term inside the integral~\eqref{eq:intwewilluse} does not depend on $y$.  This is the integral we will use to compute the moments of $A_n$.

\begin{example}\emph{\textbf{(The volume of the Voronoi cell)}
In order to demonstrate this approach we will derive the $0$th moment (i.e. the volume) of the Voronoi cell using~(\ref{eq:intwewilluse}).  Setting 
\[
f(\Qbf\wbf) = \|\Qbf\wbf\|^0 = 1
\] 
we obtain,
\begin{align*}
M_n(0) &= n\sqrt{n+1} \int^{1}_{0} \int^{y}_{0} \int^{t}_{0} \cdots \int^{t}_{0} \frac{dw_{n-1}\dots dw_1 \, dt  \, dy}{1 - t}\\
 &= n\sqrt{n+1} \int_{0}^{1} \int^{y}_{0} \frac{t^{n-1}}{1 - t} \, dt  \, dy \\
&= n\sqrt{n+1}  \int^{1}_{0} \beta(y, n, 0) \, dy = \sqrt{n+1},
\end{align*}
as required.  Here $\beta(x,a,b) =  \int_{0}^{x}  t^{a-1}(1 - t)^{b-1} \,dt$ is the incomplete beta function~\cite{Pearson_tables_of_beta_functions} and we have used the identity $\int^{1}_{0} \beta(y, n, 0) \, dy = \frac{1}{n}$.}
\end{example}

% \subsection{The second moment of the Voronoi cell}

% Setting
% \begin{align*}
% f(\Qbf\wbf) = \|\Qbf\wbf\|^2  &= \|\wbf\|^2 - \frac{(\wbf^\prime \onebf)^2}{n+1} \\
% &= t^2 + \sum_{i=1}^{n+1}w_i^2 - \frac{1}{n+1}\left( t + \sum_{i=1}^{n+1}w_i \right)^2 \\
% &= t^2 + \sum_{i=1}^{n+1}w_i^2 - \frac{1}{n+1}\left( t^2 + 2 t \sum_{i=1}^{n+1}w_i + \left(\sum_{i=1}^{n+1}w_i \right)^2 \right)\\
% &= c + d
% \end{align*}
% where
% \[
% c = \frac{n}{n+1} t^2,\qquad \text{and} \qquad d = A - \frac{2t}{n+1}B - \frac{1}{n+1}B^2,
% \]
% where $A = \sum_{i=1}^{n-1}w_i^2$ and $B = \sum_{i=1}^{n-1}w_i$.  Now the second moment is given by
% \[
% C_1 = n\sqrt{n+1} \int^{1}_{0} \int^{y}_{0} \int^{t}_{0} \cdots \int^{t}_{0} \frac{c + d}{1 - t} \,dw_{n-1}\dots dw_1 \, dt  \, dy.
% \]
% Integrating $A$, $B$ and $B^2$ over the $w_1,\dots,w_{n-1}$ gives,
% \begin{align*}
% &\int^{t}_{0} \cdots \int^{t}_{0} A \,dw_{n-1}\dots dw_1 = \frac{n-1}{3}t^{n+1},\\
% &\int^{t}_{0} \cdots \int^{t}_{0} B \,dw_{n-1}\dots dw_1 = \frac{n-1}{2}t^n, \,\,\,\, \text{and} \\
% &\int^{t}_{0} \cdots \int^{t}_{0} B^2 \,dw_{n-1}\dots dw_1 = \frac{(n-1)(3n - 2)}{12} t^{n+1}
% \end{align*}
% So integrating $d$ over the $w_1,\dots,w_{n-1}$ gives,
% \[
% \int^{t}_{0} \cdots \int^{t}_{0} d \,dw_{n-1}\dots dw_1 =  \frac{7(n-1)(n-2)}{12(n+1)}t^{n+1}.
% \]
% Also,
% \[
% \int^{t}_{0} \cdots \int^{t}_{0} c \,dw_{n-1}\dots dw_1 =  \frac{n}{n+1}t^{n+1}.
% \]
% So,
% \begin{align*}
% C_1 &=  \sqrt{n+1}\frac{n(12n + 7(n-1)(n-2))}{12(n+1)} \int^{1}_{0} \int^{y}_{0}\frac{t^{n+1}}{1 - t}  \, dt  \, dy \\
% &= \sqrt{n+1}\frac{12n + 7(n-1)(n-2)}{12(n+1)}
% \end{align*}

%\newcommand{\calV}{\mathcal{V}}
\section{The moments of $A_n$}\label{sec:powers-eucl-norm}

We now derive expressions for the $\calM_n(m)$.  Setting $f(\Qbf\xbf) = \left(\|\Qbf\wbf\|^{2}\right)^m$ in~\eqref{eq:intwewilluse} we obtain,
\begin{align*}
\frac{\calM_n(m)}{n\sqrt{n+1}} = \int_0^1 \int_0^y \int_0^t \cdots \int_0^t &\frac{\left(\|\Qbf\wbf\|^2\right)^m}{1 - t} \\
&dw_{n-1} \, \dots \, dw_1 \, dt \, dy.
\end{align*}
Now $\|\Qbf\wbf\|^2 = \|\wbf\|^2 - \frac{1}{n+1}(\wbf^\prime \onebf)^2$ and recalling that $\wbf = [t,0,w_1,\dots,w_{n-1}]'$ we can write
\begin{align*}
&\|\Qbf\wbf\|^2 \\
&= \|\wbf\|^2 - \frac{1}{n+1}(\wbf^\prime \onebf)^2 \\
&= t^2 + \sum_{i=1}^{n-1}w_i^2 - \frac{1}{n+1}\left( t + \sum_{i=1}^{n-1}w_i \right)^2 \\
&= t^2 + \sum_{i=1}^{n-1}w_i^2 - \frac{1}{n+1}\left( t^2 + 2 t \sum_{i=1}^{n-1}w_i + \left(\sum_{i=1}^{n-1}w_i \right)^2 \right)\\
&= C + D,
\end{align*}
say, where
\[
C = \left(\frac{n}{n+1} \right) t^2 \;\;\;\; \text{and} \;\;\;\; D = A - \frac{2t}{n+1}B - \frac{1}{n+1}B^2,
\]
and where,
\[
 A = \sum_{i=1}^{n-1}w_i^2 \qquad \text{and} \qquad B = \sum_{i=1}^{n-1}w_i.
\]
Now,
\begin{align*}
 \frac{\calM_n(m)}{n\sqrt{n+1}} =  \int_0^1 \int_0^y \int_0^t \cdots \int_0^t &\frac{(C+D)^m}{1 - t} \\
&dw_{n-1} \, \dots \, dw_1 \, dt \, dy,
\end{align*}
and by expanding the binomial $(C+D)^m$ we get
\begin{align*}
\frac{\calM_n(m)}{n\sqrt{n+1}} =  \int_0^1 \int_0^y \frac{1}{1 - t}\sum_{k=0}^{m}\binom{m}{k} &C^{m-k} \int_0^t \cdots \int_0^t \, D^{k} \\
&dw_{n-1} \, \dots \, dw_1 \, dt \, dy.
\end{align*}
Expanding $D^k$ as a trinomial gives
\begin{align*}
D^k &= \sum_{k_1+k_2+k_3=k} \frac{k! A^{k_1} B^{2k_3 + k_2}}{k_1! k_2! k_3!} \left(\frac{-1}{n+1}\right)^{k_2+k_3}2^{k_2}t^{k_2}  \\
&=  \sum_{a=0}^k\sum_{b=0}^{k-a} \frac{k!  A^{a} B^{2k - 2a - b}}{a! b! (k-a-b)!} \left(\frac{-1}{n+1}\right)^{k - a}2^{b}t^{b}
\end{align*}
where the second line follows by setting $k_1 = a$, $k_2 = b$ and $k_3 = k - a - b$.  In Appendix~\ref{sec:mult-type-integr} we show that the integral of $A^{a} B^{2k - 2a - b}$ over $w_1,\dots w_{n-1}$ is
\begin{equation} \label{eq:recurseint}
\begin{split}
  \int_0^t \cdots \int_0^t &A^{a} B^{2k-2a-b} dw_{n-1} \, \dots \, dw_1 \\
&= t^{n-1+2k - b} G(n-1,a,2k - 2a - b).
\end{split}
\end{equation}
where $G(n,c,d)$ satisfies the recursion given by~\eqref{eq:theGrecursion}.  So, let $P$ satisfy
\begin{align*}
P &= t^{1 - n - 2k}\int_0^t \cdots \int_0^t D^k dw_{n-1} \, \dots \, dw_1 \\
&= \sum_{a=0}^k\sum_{b=0}^{k-a} \frac{2^{b} k!G(n-1,a,2k - 2a - b)}{a! b! (k-a-b)!} \left(\frac{-1}{n+1}\right)^{k - a}.
\end{align*}
Now $C^{m-k} = \left(\frac{n}{n+1} \right)^{m-k} t^{2(m-k)}$ and
\begin{align*}
&\frac{\calM_n(m)}{n\sqrt{n+1}} \\
&= \sum_{k=0}^{m} \binom{m}{k} \left(\frac{n}{n+1} \right)^{m-k} P \int_0^1 \int_0^y \frac{t^{n - 1 + 2m}}{1 - t} \, dt \, dy \\
&= \sum_{k=0}^{m} \binom{m}{k} \left(\frac{n}{n+1} \right)^{m-k} P \int_0^1 \beta(y,n+2m,0) dy \\
&= \frac{1}{n+2m} \sum_{k=0}^{m} \binom{m}{k} \left(\frac{n}{n+1} \right)^{m-k} P.
\end{align*}
This expression is equivalent to that from~(\ref{eq:theCmformula}).


\section{Results and simulations}\label{sec:results-simulations}

We now plot the probability of coding error versus signal to noise ratio (SNR) for the lattices $A_1, A_2, A_3, A_4, A_5$ and $A_8$.  For these plots the SNR is related to noise variance according to
\[
\text{SNR} = \frac{V^{2/n}}{4\sigma^2},
\]
where $V$ is the volume of the Voronoi cell and $n$ is the dimension of the lattice~\cite[p. 167]{Viterbo_diamond_cutting_1996}.  Figure~\ref{fig:peplots} shows the `exact' probability of error (correct to 16 decimal places) computed using the moments $\calM_n(m)$ and~\eqref{eq:summomentproberror} (solid line).  The number of moments needed to ensure a certain number of decimal places accuracy depends on $n$ and also on the noise variance $\sigma^2$.  At most 321 moments where needed for Figure~\ref{fig:peplots}.  We also display the probability of error computed approximately by Monte-Carlo simulation (dots).  %We have used the fast nearest point algorithm for $A_n$ described in~\cite{McKilliam2009CoxeterLattices} and~\cite[p. 448]{SPLAG}.
The simulations are iterated until 5000 error events occur.

The plot also displays an approximation for the probability of error for the 8-dimensional $E_8$ lattice.  The approximation is made in the usual way by applying the union bound to the minimal vectors of the lattice~\cite[p.~71]{SPLAG}.  The $E_8$ lattice has 240 minimal vectors of length $\sqrt{2}$.  The packing radius of $E_8$ is therefore $\rho = \sqrt{2}/2$.  Applying the union bound the probability of error satisfies
\newcommand{\erfc}{\operatorname{erfc}}
\newcommand{\erf}{\operatorname{erf}}
\[
P_E \leq 240\erfc\left( \frac{\rho}{\sqrt{2}\sigma} \right) = 240\erfc\left(\frac{1}{2\sigma}\right)
\]
where $\erfc(x) = 1 - \erf(x)$ is the complementary error function.  For the $E_8$ lattice this approximation is an upper bound because the relevant vectors of $E_8$ (those vectors that define the Voronoi cell) are precisely the 240 minimal vectors.  %The second moment of this representation of $E_8$ is $\frac{929}{1620}$ so SNR is related to $\sigma^2$ by $\text{SNR} = \frac{929}{3240\sigma^2}$.

%For $\Lambda_{24}$ there are $196560$ minimal vectors each of length $2$.  The packing radius is $\rho = 1$.  An approximation for the probability of error is
%\[
%P_E \approx 196560\erfc\left( \frac{\rho}{\sqrt{2}\sigma} \right) = 196560\erfc\left(\frac{1}{\sqrt{2}\sigma}\right).
%\]
% The second moment of this representation of $\Lambda_{24}$ is approximately $24 \times 0.065771$.  This was computed numerically by Conway and Sloane~\cite[p. 61]{SPLAG}.  The relationship between SNR and $\sigma^2$ is $\text{SNR} = 4 \times 0.065771 \sigma^{-2}$.

% We now plot the probability of coding error versus signal to noise ratio (SNR) for the lattices $A_1, A_2, A_3$ and $A_4$.  We assume that codes are constructed from these lattices using a \emph{Voronoi constellation}~\cite{Conway1983VoronoiCodes} of size $2^n$.  This corresponds to a rate of $1$ bit per dimension (or symbol).  The shaping region of these constellations is $2\vor(A_n)$, i.e. the Voronoi cell of $A_n$ scaled by a factor of $2$.  The average power of these constellations can be approximated by four times the second moment $4\calM_n(1)$.  This approximation is conservative as Voronoi constellations can have average power smaller than the second moment of the shaping region~\cite{Conway1983VoronoiCodes}.  The approximation becomes more accurate as the code rate and correspondingly the volume of the shaping region grows.  %In proving that lattice codes using lattice decoding can achieve capacity Erez and Zamir~\cite{Erex2004_lattice_decoding} employ a common dither between transmitter and receiver. This is to ensure that the average power is \emph{exactly} the second moment of the shaping region.  For this reason we think that this approximation is valid.
% The SNR is then given by
% \[
% \text{SNR} = \frac{4\calM_n(1)}{n \sigma^2} = \frac{n+3}{3\sqrt{n+1}\sigma^2}
% \]
% where $\sigma^2$ is the noise variance.  %As we have assumed that 1 bit is transmitted per symbol the SNR at channel capacity is equal to one.

% %Given a lattice with inradius $\rho$ and Voronoi cell having volume $V$ we define the SNR as
% %\[
% %\frac{V_n}{\sigma^2(n+2)(\log(V_n) - \log(V) + n\log(\rho))}
% %\]
% %where $V_n$ is the volume of the $n$ dimensional hypersphere and the logarithms are base $2$.

% Figure~\ref{fig:peplots} shows the `exact' probability of error (correct to 16 decimal places) computed using the moments $\calM_n(1)$ and~\eqref{eq:summomentproberror} (solid line).  The number of moments needed to ensure a certain number of decimal places accuracy depends on $n$ and also on the noise variance $\sigma^2$.  At most 196 moments where needed for Figure~\ref{fig:peplots}.  We also display the probability of error computed approximately by Monte-Carlo simulation (dots).  %We have used the fast nearest point algorithm for $A_n$ described in~\cite{McKilliam2009CoxeterLattices} and~\cite[p. 448]{SPLAG}.
% The simulations are iterated until 500 error events occur.

% We have also plotted approximations for the probability of error for codes constructed from the 8-dimensional $E_8$ lattice and the 24-dimensional Leech lattice $\Lambda_{24}$.  The approximation are made in the usual way by applying the union bound to the minimal vectors of the lattice~\cite[p.~71]{SPLAG}.  The $E_8$ lattice has 240 minimal vectors of length $\sqrt{2}$.  The packing radius of $E_8$ is therefore $\rho = \sqrt{2}/2$.  By the union bound the probability of error satisfies
% \newcommand{\erfc}{\operatorname{erfc}}
% \newcommand{\erf}{\operatorname{erf}}
% \[
% P_E \leq 240\erfc\left( \frac{\rho}{\sqrt{2}\sigma} \right) = 240\erfc\left(\frac{1}{2\sigma}\right)
% \]
% where $\erfc(x) = 1 - \erf(x)$ is the complementary error function.  The second moment of this representation of $E_8$ is $\frac{929}{1620}$ so SNR is related to $\sigma^2$ by $\text{SNR} = \frac{929}{3240\sigma^2}$.

% For $\Lambda_{24}$ there are $196560$ minimal vectors each of length $2$.  The packing radius is $\rho = 1$.  The union bound on the probability of error is
% \[
% P_E \leq 196560\erfc\left( \frac{\rho}{\sqrt{2}\sigma} \right) = 196560\erfc\left(\frac{1}{\sqrt{2}\sigma}\right).
% \]
% The second moment of this representation of $\Lambda_{24}$ is approximately $24 \times 0.065771$.  This was computed numerically by Conway and Sloane~\cite[p. 61]{SPLAG}.  The relationship between SNR and $\sigma^2$ is $\text{SNR} = 4 \times 0.065771 \sigma^{-2}$.

\begin{figure*}[tp]
	\centering
		\includegraphics{plots/peplots-1.mps}
		\caption{The probability of error versus SNR for $A_1 \simeq \ints$, $A_2$, $A_3\simeq D_3, A_4, A_5, A_8$ and $E_8$.}
		\label{fig:peplots}
\end{figure*}


\section{Conclusion}

Recursive formulae for the moments of the Voronoi cell of the lattice $A_n$ were found.  These enable accurate prediction of the performance of codes constructed from $A_n$.  The formulae were obtained by observing that the Voronoi cell of $A_n$ is a \emph{zonotope}, i.e. it can be described as an orthogonal projection of the $(n+1)$-dimensional hypercube.  It is possible that the techniques developed here can be applied to other \emph{zonotopal lattices}~\cite{Vallentin_space_tiling_zonotope_2004}, i.e. those lattices with Voronoi cells that are zonotopes.

\appendix


\subsection{A multinomial type integral over a hypercube}\label{sec:mult-type-integr}

In~(\ref{eq:recurseint}) we required to evaluate integrals of the form
\begin{align*}
F(n-1,a,&2k - 2a - b) \\
&= \int^{t}_{0} \cdots \int^{t}_{0} A^a B^{2k - 2a - b} \,dw_{n-1}\cdots dw_{1},
\end{align*}
or equivalently, integrals of the form
\[
F(n,c,d) = \int^{t}_{0} \cdots \int^{t}_{0} \left(\sum_{j=1}^{n} x_j^2\right)^c \left( \sum_{i=1}^{n} x_i \right)^d \,dx_1\cdots dx_{n}
\]
where $n, c$ and $d$ are integers.  We will find a recursion describing this integral.  Write
\begin{align*}
&F(n,c,d) \\
&= \int^t_0 \cdots \int^t_0 \left(x_n^2 + \sum_{j=1}^{n-1} x_j^2\right)^c \left( x_n + \sum_{i=1}^{n-1} x_i \right)^d \,dx_1\cdots dx_n.
\end{align*}
Expanding the two binomials gives
\begin{align*}
&F(n,c,d) \\
&=  \int^t_0 \cdots \int^t_0  \sum_{c'=0}^{c} \binom{c}{c'} x_n^{2c'} \left(\sum_{j=1}^{n-1} x_j^2\right)^{c-c'}  \\
& \hspace{2.6cm}  \sum_{d'=0}^{d}\binom{d}{d'} x_n^{d'} \left(\sum_{i=1}^{n-1} x_i \right)^{d-d'} \,dx_1\cdots dx_{n}  \\
&= \sum_{c'=0}^{c} \sum_{d'=0}^d \int^t_0 \cdots \int^t_0 \binom{c}{c'} \binom{d}{d'} x_n^{2c'+d'} \\ 
& \hspace{2.6cm} \left(\sum_{j=1}^{n-1} x_j^2\right)^{c-c'} \left(\sum_{i=1}^{n-1} x_i \right)^{d-d'} \,dx_1\cdots dx_{n}.
\end{align*}
Integrating the $x_n$ term gives
\begin{align*}
F(&n,c,d) \\
&= \sum_{c'=0}^{c} \sum_{d'=0}^{d} \binom{c}{c'}\binom{d}{d'} \frac{t^{2c'+d'+1}}{2c'+d'+1} \int^t_0 \cdots \int^t_0 \\
& \hspace{1cm} \left(\sum_{j=1}^{n-1}x_j^2\right)^{c-c'}\left(\sum_{i=1}^{n-1} x_i \right)^{d-d'} \,dx_1\cdots dx_{n-1}.
\end{align*}
Note that
\begin{align*}
&F(n-1,c-c',d-d')  \\
&= \int^t_0 \cdots \int^t_0 \left(\sum_{j=1}^{n-1}x_j^2\right)^{c-c'}\left(\sum_{i=1}^{n-1} x_i \right)^{d-d'} \,dx_1\cdots dx_{n-1}.
\end{align*}
So $F(n,c,d)$ satisfies the recursion
\begin{align*}
&F(n,c,d) \\
&= \sum_{c'=0}^{c} \sum_{d'=0}^{d} \binom{c}{c'}\binom{d}{d'} \frac{t^{2c'+d'+1}}{2c'+d'+1}F(n-1,c-c',d-d')
\end{align*}
with the initial conditions
\[
F(1,c,d) = \frac{t^{2c+d+1}}{2c+d+1} \qquad \text{and} \qquad F(n,0,0) = t^n.
\]
The $F(n,c,d)$ can be written as $t^{n+2c+d}G(n,c,d)$ where $G(n,c,d)$ is rational.  To see this write
\begin{align*}
&F(n,c,d) \\
&=  \sum_{c'=0}^{c} \sum_{d'=0}^{d} \binom{c}{c'}\binom{d}{d'} \frac{G(n-1,c-c',d-d') t^{2c'+d'+1}}{(2c'+d'+1) t^{1-n-2(c-c')-d+d'}} \\
&=  t^{n+2c+d}\sum_{c'=0}^{c} \sum_{d'=0}^{d} \binom{c}{c'}\binom{d}{d'} \frac{G(n-1,c-c',d-d')}{2c'+d'+1} \\
&=  t^{n+2c+d}G(n,c,d).
\end{align*}
Now $G(n,c,d)$ is the rational number satisfying the recursion
\[
G(n,c,d) = \sum_{c'=0}^{c} \sum_{d'=0}^{d} \binom{c}{c'}\binom{d}{d'} \frac{G(n-1,c-c',d-d')}{2c'+d'+1}
\]
with the initial conditions
\[
G(1,c,d) = \frac{1}{2c+d+1} \qquad \text{and} \qquad G(n,0,0) = 1.
\]

\subsection{Solving this recursion for fixed $d$ and $c$}\label{sec:solv-this-recurs}
\newcommand{\calG}{\mathcal G}

For fixed $d$ and $c$ this recursion can be solved explicitly.  Write
\begin{align*}
G(n,c,d) &= G(n-1,c,d) \\
&\hspace{0.2cm}+ \sum_{ (c',d') \neq (0,0)} \binom{c}{c'}\binom{d}{d'} \frac{G(n-1,c-c',d-d')}{2c'+d'+1}
\end{align*}
where the sum $\sum_{ (c',d') \neq (0,0)}$ is over all $0 \leq c' \leq c$ and $0 \leq d' \leq d$ except when both $d$ and $c$ are zero.  Denote by $\calG(z,c,d)$ the $z$-transform of $G(n,c,d)$.  Taking the $z$-transform of both sides in the equation above gives
\begin{align*}
&\calG(z,c,d) \\
&= \frac{z^{-1}}{1-z^{-1}} \sum_{ (c',d') \neq (0,0)} \binom{c}{c'}\binom{d}{d'} \frac{\calG(z,c-c',d-d')}{2c'+d'+1}.
\end{align*}
So the $z$-transform $\calG(z,c,d)$ satisfies this recursive equation.  The initial condition is $\calG(z,0,0) = \frac{z^{-1}}{1 - z^{-1}}$.  By inverting this $z$-transform and using the resultant expressions in~\eqref{eq:theCmformula} we obtain formulae in $n$ for the moment $\calM_n(m)$.  This procedure was used to generate the formula described in Section~\ref{sec:main-result}.  Mathematica 8.0 was used to perform these calculations.  We have computed formula for $m = 0, 1, \dots, 40$ this way, but it becomes computationally infeasible for large $m$.

We have observed the following property.  The formula for $M_n(m)$ appears to always be in the form
\[
\frac{p(n)}{(1+n)^{m-1/2} d}
\] 
where $p(n) = a_0 + a_1n + \dots a_{2m} n^{2m}$ is a polynomial of degree $2m$ and $d$ is a positive integer.  The following appears to be true
\[
\frac{d}{a_{2m}} = 12^m,
\]
that is, the integer in the denominator $d$ is equal to the highest order coefficient $a_{2m}$ of the numerator polynomial $p(n)$ multiplied by $12^m$.  This leads us to make the following conjecture about the moments of $A_n$ when the dimension $n$ gets large.

\begin{conjecture}
For any fixed $m$,
\[
\frac{M_n(m)}{n^{m+1/2}} \rightarrow \frac{1}{12^{m}} 
\]
as $n \rightarrow \infty$.
\end{conjecture}

It might be hoped that this conjecture leads to an asymptotic result about the probability of error of lattice codes constructed from $A_n$ when $n$ is large.  However, this does not appear to be the case when the variance of the noise $\sigma^2$ is less than one.  In this case, the term $\sigma^n$ on the denominator of~(\ref{eq:summomentproberror}) shrinks with $n$.  So, when $\sigma < 1$, the number of moments required to produce an accurate estimate of the probability of error increases with $n$.

\small
\bibliography{bib}

\begin{IEEEbiographynophoto}{Robby G. McKilliam}
was born in Brisbane, Queensland, Australia in 1983. He received the B.Sc. degree in mathematics and the B.E. degree (Hons. I) in computer systems engineering from the University of Queensland, Brisbane, Australia in 2006.  In December 2010 he completed his PhD at the University of Queensland, Brisbane, Australia.  He is now at the Institute for Telecommunications Research at the University of South Australia, Adelaide.  His fields of interest are lattice theory, number theory, estimation theory and signal processing and communications.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Ramanan Subramanian}
received the Bachelor of Technology degree in Electrical Engineering from the Indian Institute of Technology, Madras in 2003, the Master of Science and PhD degrees in Electrical and Computer Engineering from the Georgia Institute of Technology, Atlanta, USA in 2006 and 2009 respectively. Since late 2009, he has been working as a research fellow at the Institute for Telecommunications Research (ITR) at the University of South Australia in Adelaide. His research interests include wireless networking, information theory, queuing theory, and statistics.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{Emanuele Viterbo}
received his degree (Laurea) in Electrical Engineering
in 1989 and his Ph.D. in 1995 in Electrical Engineering, both from the
Politecnico di Torino, Torino, Italy.  From 1990 to 1992 he was with the
European Patent Office, The Hague, The Netherlands, as a patent examiner
in the field of dynamic recording and error-control coding. Between 1995
and 1997 he held a post-doctoral position in the Dipartimento di
Elettronica of the Politecnico di Torino. In 1997-98 he was a
post-doctoral research fellow in the Information Sciences Research
Center of AT\&T Research, Florham Park, NJ, USA. He became first
Assistant Professor (1998) then Associate Professor (2005) in
Dipartimento di Elettronica at Politecnico di Torino. In 2006 he became
Full Professor in DEIS at University of Calabria, Italy. From 2010 he is
Full Professor in the ECSE Department and Associate Dean for Research
Training in the Faculty of Engineering at Monash University, Melbourne,
Australia.
Prof. Emanuele Viterbo is a 2011 Fellow of the IEEE,  a ISI Highly Cited
Researcher and Member of the Board of Governors of the IEEE Information
Theory Society (2011-2013). He is Associate Editor of IEEE Transactions
on Information Theory, European Transactions on Telecommunications and
Journal of Communications and Networks, and Guest Editor for IEEE
Journal of Selected Topics in Signal Processing: Special Issue Managing
Complexity in Multiuser MIMO Systems.
In 1993 he was visiting researcher in the Communications Department of
DLR, Oberpfaffenhofen, Germany. In 1994 and 1995 he was visiting the
cole Nationale Suprieure des Telcommunications (E.N.S.T.), Paris. In
2003 he was visiting researcher at the Maths Department of EPFL,
Lausanne, Switzerland. In 2004 he was visiting researcher at the
Telecommunications Department of UNICAMP, Campinas, Brazil. In 2005,
2006 and 2009 he was visiting researcher at the ITR of UniSA, Adelaide,
Australia. In 2007 he was visiting fellow at the Nokia Research Center,
Helsinki, Finland.
Dr. Emanuele Viterbo was awarded a NATO Advanced Fellowship in 1997 from
the Italian National Research Council. His main research interests are
in lattice codes for the Gaussian and fading channels, algebraic coding
theory, algebraic space-time coding, digital terrestrial television
broadcasting, and digital magnetic recording.
\end{IEEEbiographynophoto}

\begin{IEEEbiographynophoto}{I. Vaughan L. Clarkson}
was born in Brisbane,
Queensland, Australia, in 1968. He received the
B.Sc. degree in mathematics and the B.E. degree
(Hons. I) in computer systems engineering from
The University of Queensland, Brisbane, in 1989
and 1990, respectively, and the Ph.D. degree in
systems engineering from The Australian National
University, Canberra, in 1997.
In 1988, he was with the Defence Science and
Technology Organisation, Adelaide, Australia, ﬁrst
as a Cadet, later as a Professional Ofﬁcer, and ﬁnally
as a Research Scientist. From 1998 to 2000, he was a Lecturer at The University
of Melbourne, Melbourne, Australia. From 2000 to 2008, he was a Senior
Lecturer in the School of Information Technology and Electrical Engineering
at The University of Queensland. In 2008, he was promoted to Reader. In 2005,
he was a Visiting Professor in the Department of Electrical and Computer
Engineering, The University of British Columbia, Vancouver, Canada. His
research interests include statistical signal processing for communications and
defense, image processing, information theory, and lattice theory.
\end{IEEEbiographynophoto}

\end{document}
